\begin{abstract}
	
%The use of more relevant metrics of software systems could 
%improve various software engineering tasks, but identifying 
%relationships among metrics is difficult and can be very time 
%consuming. Recommender systems can help with this decision-making process; 
%many applications have utilized these systems to improve the performance of their applications. 
%To investigate the potential benefits of recommender systems in regression testing, 
%we implemented an item-based collaborative filtering recommender 
%system that uses user interaction data and application change history 
%information to develop a test case prioritization technique. 
%To evaluate our approach, we performed an empirical study using 
%three applications with multiple versions by comparing four control techniques. 
%Our results indicate that our recommender system can help improve 
%the effectiveness of test prioritization; the performance of 
%our approach was particularly noteworthy when we were under a time constraint.	

%Performance regression is a consequence of software evolution. 
%Code quality and change history play a significant role in detecting performance regression.
%Small changes can significantly degrade software performance. 
%During developing time, some times developers negligent code quality and performance, 
%this carelessness can be a cause of future regression, which will needs 
%more cost and effort to fix in later stages.
%Performance regression testing is an effective way to reveal such issues
%in early stages. 
%Yet because of its high overhead, this activity is usually performed infrequently. 
%Consequently, when performance regression issue is spotted at a certain point, multiple commits might
%have been merged since last testing. Developers have to spend extra
%time and efforts narrowing down which commit caused the problem. 
%Existing efforts try to improve performance regression testing
%efficiency through test case reduction or prioritization.
%In this paper, we propose a new context aware recommender system, which 
%analyses code quality and risk factors and will return a ranking for
%risky components. The analysis consider change history of the system,
%code metrics and number of execution time and interaction level for each component.
%Based on the obtained ranking from our recommender system we will test high risks 
%components first while delaying or skipping testing on low-risk commits.
\end{abstract}

