\vspace*{4pt}
\section{Empirical Study}
\label{sec:study}

As stated in Section \ref{sec:introduction}, the goal of
this study is to assess our regression testing approach in terms 
of finding the ordered list of test cases that cover most risky parts 
of the system with considering the test cost.
To investigate our research questions, we performed
an empirical study.The following subsections present our objects of analysis, 
study setup, threats to validity, and data analysis.
In particular, we address the following research questions:

\begin{itemize}
\item[RQ1:] Are final scores effective at identifying high risky classes?
\item[RQ2:] Can our recommender system be useful for 
improving performance regression testing techniques?
\item[RQ3:] How effective is our proposed approach in terms of cost saving?
\end{itemize}

\noindent


%\subsection{Hypothesis}
%\begin{itemize}
%	\item[H1] Increase in complexity metrics of a component C correlates with
%	the regression of C.
%	\item[H2] Having change history of a component C 
%	is a evidence for risk of future regression of C.
%	\item[H3] There is a relation between number of 
%	interactions of a class C to the regression of C.
%\end{itemize}


\subsection{Objects of Analysis}
\label{sec:objects}

We used three web applications to evaluate our proposed technique. 
Table ~\ref{tab:AUTs} lists these applications.
% paraf beshe
Our first object of analysis is DASCP, which is 
a digital archive and scan software for civil projects;
we obtained this application from a private company. DASCP is
a web based application designed to store civil project contracts,
which includes the technical information of civil and construction
projects such as project plans and relevant associated information.
DASCP includes an access control system and provides two types
of access rights: one user group has permission to edit or insert
a project’s information or upload maps and contract sheets and the
other user group is only allowed to view the data and details about
the projects.

Our second application is nopCommerce, which is a widelyused open source e-commerce shopping cart web application with
more than 1.8 million downloads. This application is written in
ASP.Net MVC and uses Microsoft SQL Server as a database system [1].
Our last application is Coevery, which is an open source customer relationship management (CRM) system written in ASP.Net.
This application provides an easy framework for users to create
their own customized modules without having to write any code.
The UI design of Coevery has been developed by AngularJS and
Orchard Technologies [2].


	
	\begin{table}
		\caption{Subject Applications Properties}
		\begin{center}
			\begin{tabular}{|l|c|c|c|} \hline
				\textbf{Metrics}  & \textbf{DASCP} & \textbf{nopCommerce} 
				& \textbf{Coevery} \\\hline \hline
				Classes   & 107  & 1,919& 2,258 \\\hline
				Files  & 201  & 1,473 & 1,875 \\\hline
				Functions & 940  & 21,057 & 13,041 \\\hline
				LOC & 35,122 & 226,354 &120,897 \\\hline
				Sessions  & 748 & 1310 & 274 \\\hline
				Faults  & 35 & 70 & 30\\\hline
				Version  & 3 & 23 & 3 \\\hline
				Test Cases & 95& 543 & 1,120 \\\hline
				Installations & 3 & 2 & 1 \\\hline
			\end{tabular}
			\end {center}
			\label{tab:AUTs}
		\end{table}
		
Table 1 lists the applications under study and their associated
data: “Classes” (the number of class files), “Files” (the number of
files), “Functions” (the number of functions/methods), “LOC” (the
number of lines of code), “Sessions” (the number of user sessions
that we collected), “Faults” (the number of seeded faults), “Version” (the number of versions), “Test Cases” (the number of test
cases), and “Installations” (the number of different locations where
the applications were installed).		


\subsection{Variables and Measures}
\label{sec:measures}

\subsubsection{Independent Variables}
\label{sec:independent}

To investigate our research questions, we manipulated one independent variable: 
prioritization technique. We considered five
different test case prioritization techniques, which we classified
into two groups: control and heuristic. Table ~\ref{tab:techniques2} summarizes these
groups and techniques. The second column shows prioritization
techniques for each group, and the third column is a 
short description of prioritization techniques.


\begin{table*}[!ht]
	\caption{Test Case Prioritization Techniques}
	\vspace*{-10pt}
	\begin{center}
		\begin{tabular}{|l|l|l|}\hline
			Group & Technique & Description \\ \hline
			\multirow{4}{*}{Control} 
			& Change history-based ($T_{ch}$) & Test case prioritization based on change impact analysis score\\
			& Most frequent web forms-based ($T_{mfw}$)&  Test case prioritization based on value of frequency for each web form.\\
			& Most frequent components-based ($T_{mfc}$) &  Test case prioritization based on value of frequency for each component.\\
			& Random ($T_{r}$) &  Test execution in random order.\\\hline			
			\multirow{1}{*}{Heuristic} 
			& Hybrid collaborative filtering-based ($T_{hcf}$)& Test case prioritization based on the proposed technique. \\\hline
		\end{tabular}
		\end {center}
		\label{tab:techniques2}
		\vspace*{-5pt}
	\end{table*}

As shown in Table~\ref{tab:techniques2}, we considered four control techniques and 
one heuristic technique. For our heuristic technique, we used the approach 
explained in Section~\ref{sec:method},


%Our empirical study manipulated one independent
%variable, test generation technique.
%We considered one control technique and one heuristic technique.
%
%The control technique generates all possible linearly independent
%paths without using any particular regression test case generation
%heuristics. This technique serves as an experimental control.  
%The heuristic technique generates regression test cases using
%the program slices explained in earlier sections. 

\subsubsection{Dependent Variable and Measures}
\label{sec:dependent}

Our dependent variable RQ1 is the average percentage of fault detection (APFD)
referring to the average percentage of faults detected during the test suite execution. 
The range of APFD is from 0 to 100, the higher value indicating better prioritization technique. 
Given $T$ as a test suite with $n$ test cases and $m$ number of faults, 
$F$ as a collection of detected faults by $T$ and
$TF_{i}$ as the first test case that catches the fault $i$, 
we calculate APFD ~\cite{apfd} as follows:

\[
{APFD = 1- \frac {{TF_{1} + TF_{2} + ... + TF_{m}}} {nm} + \frac{1}{2n}}
\]

RQ2 seeks to measure the effectiveness of our proposed approach
when we have constrained resources, which means that we need to evaluate 
the effectiveness of our approach using a different metric. 
Qu et al.~\cite{myra} defined the normalized metric of APFD, which is the
area under the curve when the numbers of test cases or faults are not consistent. 
The NAPFD formula is as follows:

\[
{APFD_{c} = \frac { \sum_{i=1}^{m} (f_{i} \times (\sum_{j=TF_{i}}^{n} (t_{j} - \frac{1}{2} t_{TF_{i}})) )} 
	{\sum_{i=1}^{n}{t_{i}} \times \sum_{i=1}^{m}{f_{i}}}}
\]

In this formula, $n$ is percentage of the test suite run, 
$m$ represents the total number of faults found by all test cases,
$TF_{i}$ indicates the same parameter as AFPF, and 
$p$ is the number of faults detected by percentage of our
budget divided by total number of detected faults when 
running 100\% of test cases.  


\subsection{Experiment Setup}
\label{sec:setup}

\subsection{Data Collection}
To perform our experiment we collected different types of data from our AUTs.
Our first dataset is change history. 
The second one is class dependency and the last one is 
test case code coverage information.
We explain the data collection processes
in the following subsections.

\subsubsection{Collect Code Change History}
We had to take three steps to measure change impact. 
First, we needed a clear understanding of the applications with respect to their changes.
For instance, we needed to check whether a change 
was just renaming a variable or component, the addition of some comments, 
or an alternation of code by adding or deleting functions. 
Then, we needed to check whether changes had been made in the current version, 
and finally, we tested a recently changed system~\cite{change3}. 
In order to collect change history information for training, 
we used all versions of our applications.

In our study, we collected the change history of our three applications. 
We chose ten metrics that have high correlations with bugs.
Most of these metrics have been used in bug detection research, and they
are known to be good indicators for locating bugs 
~\cite{sungmicro, shihab12, raimund, change1, change2}. 
Table~\ref{tab:historyMetrics} shows the applied change metrics in this study. \\

\begin{table}[!ht]
	\caption{Change metrics used to evaluate risk in this study}	
	\vspace*{3pt}
	%\begin{tabular*} {.8\linewidth}{@{\extracolsep{\fill}}l|l|}
	\begin{tabular} {|l|l|} \hline
		\textbf{Metrics Name} & \textbf{Description} \\\hline \hline
		Revision & Number of revision of a component  \\\hline
		LOC Added&   Added lines of code \\\hline
		Max LOC Added  & Maximum added lines of code \\\hline
		AVE LOC Added  & Average added lines of code \\\hline
		LOC Deleted  & Deleted lines of code  \\\hline
		Max LOC Deleted & Maximum deleted line\\\hline
		AVE LOC Deleted & Average deleted lines of code \\\hline
		Code Churn & Sum of change in all revisions \\\hline
		Age & \parbox[t]{5cm}{Age of the component \\ in days from last release} \\\hline
		Time & \parbox[t]{5cm} {Time of the change \\ in dd-mm-yyyy format} \\\hline		
	\end{tabular}
	\label{tab:historyMetrics}
\end{table}

\subsubsection{Collect Class Dependency}
To extract class dependency information 
we used the Understand tool []. The Understand tool
extracts 24 file-level and 18 class-level metrics 
such as Chidamber and Kemerer [5] and Object-Oriented metrics. If
a file has more than one class, we derived file-level
metrics from multiple class-level metrics. 
The Understand tool mostly provides two kinds of metrics: Avg* and Count*. 
To generate file-level metrics from multiple classes in a file, we
averaged Avg* class-level metrics. However, when we get
file-level metrics from Count* classs-level metrics, we added
the values together. We used all 42 metrics for our experiments.
The output of Understand is a list of classes with their numerical 
value of number of its references, from and to entities. \\

\subsubsection{Collect Code Coverage and Test Cost}

We collect code coverage data for test cases using the Visual Studio
Test Analyzer tool. Also we used the same tool to collect the 
test case execution time. After collecting all required information, 
we created a SQL database and we stored them into a datatable. 
Our datatable records information about which tests exercised each class
and the time its needed to be executed. 
We assigned a unique identifier to each class to provide
a key for classes, which makes the mapping process much easier.
Table ~\ref{xx} shows a schema of our datatable. 

  
%We collected the code coverage
%data for test cases executed against the System Under
%Test (SUT) using the code coverage recorder that Dy¬
%namics Ax provides as a part of its framework. We stored
%the code coverage data in the SQL database that lists
%information about which tests exercised which methods
%in the program. For each class and method, unique
%identifier values were assigned. This not only provides
%a key for the class or method tables that easily map
%to foreign keys in the related tables, but also provides
%a way to hide the actual names, protecting Microsoft’s
%intellectual property and sensitive data. A partial data
%set we collected is shown in Table III.
%In Table III, the first two columns, “ ClassID” and
%“ MethodID” , show the unique identifier values assigned
%to each class and method in the system. “ No. of Dep.”
%is the number of dependency relationships for a given
%method, “ LOC” is the number of lines of code for a
%given class, and ” CC” is the code complexity metric
%we defined in Section III-B. The “ Fault” columns list
%Boolean values indicating whether the fault occurred for
%a given method: 0 indicates no faults occurred, and 1
%indicates faults occurred. The ‘TestID” columns also list
%Boolean values indicating whether test cases exercised
%a given method or not: 0 indicates that test cases are not
%exercised, and 1 indicates that test cases are exercised.

% from ryan paper




%In addition, we collected 15 HMs following Moser et al.’s
%approach [23]. All HMs were collected from the change history stored in Eclipse CVS repository2 during the metrics
%extraction period as shown in Figure 2.
%Table 4 lists 15 HMs used in our experiments. The Refactorings metrics indicates if a file change is refactoring [23].
%This is determined by mining CVS commit logs: if they contain the keyword ‘refactor’, we assume it is a refactoring. We
%counted the number of all refactored revisions of a file in the
%metrics extraction period. The Age metric indicates the period of file existence [23]. The BugFixes metric represents
%the defect numbers in the metrics extraction period. To
%compute this, we mined commit logs to search explicit bug
%IDs in the logs. Then, we checked the bug reports, and if
%they were fixed bugs (not feature enhancement), we marked
%the change as bug-fix. In addition, we searched for specific
%keywords, bug or fix 3, which indicate bug fix changes [23].
%If change logs had such keywords, we marked the changes as
%bug-fixes.

  


\subsection{Fault Injection}

We evaluated our approach by running it against  
tests with and without regressions issues.
To have tests with and without regressions, we injected source code
level faults that are similar to the developer mistakes. To do this, we asked 
volunteer students to seed faults randomly into the system. 
%the following performance regressions were injected into our objects :\\

% noe fault hayee ro ke inject kardam inja minevisam

%\textbf{• A: Increasing Memory Usage.} Adding a field to
%an object increases the memory usage. Because the
%object is created many times, such a change
%would cause a large increase of memory usage.\\
%\textbf{• B: Increasing CPU Usage.} Additional calculation
%is added to the source code of objects. The source code 
%with additional calculation is frequently executed during the performance test.\\
%\textbf{• C: Removing column index.} Column index are
%used for frequently queried columns. Such regression
%can only be identified during a large-scale performance
%test since only the workload that exercises the corresponding query would 
%suffer from the performance regression. 
%A column index in the database is removed
%to cause slower database requests.\\
%\textbf{• D: Removing text index.} Similar to C, a text index
%is often used for searching text data in the database. A
%database text index is removed to cause slower database
%requests.\\
%\textbf{• E: Increasing I/O access time.} Accessing I/O storage devices, 
%such as hard drives, are usually slower
%than accessing memory. Adding additional I/O access may cause performance regressions. 
%For example, adding unnecessary log statements is one of the causes
%of performance regressions. Logging statements
%are added to the source code that is frequently 
%executed in order to introduce this performance regression.






